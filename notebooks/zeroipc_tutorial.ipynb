{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ZeroIPC Tutorial: High-Performance Shared Memory IPC\n",
    "\n",
    "This notebook demonstrates ZeroIPC, a lock-free shared memory IPC library that enables zero-copy data sharing between processes.\n",
    "\n",
    "## Table of Contents\n",
    "1. [Installation & Setup](#1-installation--setup)\n",
    "2. [Core Concepts](#2-core-concepts)\n",
    "3. [Basic Data Structures](#3-basic-data-structures)\n",
    "4. [Codata Structures](#4-codata-structures)\n",
    "5. [Cross-Process Communication](#5-cross-process-communication)\n",
    "6. [Performance Comparison](#6-performance-comparison)\n",
    "7. [Best Practices](#7-best-practices)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Installation & Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install ZeroIPC (run once)\n",
    "import sys\n",
    "!{sys.executable} -m pip install -e /home/spinoza/github/beta/zeroipc/python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from multiprocessing import Process\n",
    "\n",
    "# Import ZeroIPC components\n",
    "from zeroipc import (\n",
    "    Memory, Array, Queue, Stack, Table,\n",
    "    Map, Set, Pool, Ring, Future, Lazy, Stream, Channel\n",
    ")\n",
    "\n",
    "print(\"ZeroIPC successfully imported!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Core Concepts\n",
    "\n",
    "### Shared Memory\n",
    "ZeroIPC uses POSIX shared memory for zero-copy data sharing between processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create shared memory region\n",
    "mem = Memory(\"/demo_memory\", 10 * 1024 * 1024)  # 10MB\n",
    "print(f\"Created shared memory: {mem}\")\n",
    "\n",
    "# The metadata table tracks all data structures\n",
    "print(f\"\\nTable entries: {mem.table.size()} / {mem.table.capacity()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Basic Data Structures\n",
    "\n",
    "### Array: Fixed-size contiguous storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an array of floats\n",
    "temperatures = Array(mem, \"temperatures\", 100, dtype=np.float32)\n",
    "\n",
    "# Write some data\n",
    "for i in range(10):\n",
    "    temperatures[i] = 20.0 + i * 0.5\n",
    "\n",
    "# Read data\n",
    "print(f\"Temperature readings: {temperatures[:10]}\")\n",
    "print(f\"Array size: {len(temperatures)} elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Queue: Lock-free FIFO buffer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a message queue\n",
    "messages = Queue(mem, \"message_queue\", capacity=10, dtype=np.int32)\n",
    "\n",
    "# Producer: push messages\n",
    "for i in range(5):\n",
    "    if messages.push(100 + i):\n",
    "        print(f\"Pushed message: {100 + i}\")\n",
    "\n",
    "print(f\"\\nQueue size: {messages.size()}\")\n",
    "\n",
    "# Consumer: pop messages\n",
    "while not messages.empty():\n",
    "    msg = messages.pop()\n",
    "    print(f\"Received message: {msg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Map: Hash table with string keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a configuration map\n",
    "config = Map(mem, \"config\", capacity=16, dtype=np.float32)\n",
    "\n",
    "# Set configuration values\n",
    "config.set(\"threshold\", 0.95)\n",
    "config.set(\"timeout\", 30.0)\n",
    "config.set(\"rate\", 100.0)\n",
    "\n",
    "# Read configuration\n",
    "print(\"Configuration:\")\n",
    "for key in [\"threshold\", \"timeout\", \"rate\"]:\n",
    "    value = config.get(key)\n",
    "    if value is not None:\n",
    "        print(f\"  {key}: {value}\")\n",
    "\n",
    "print(f\"\\nMap contains 'threshold': {config.contains('threshold')}\")\n",
    "print(f\"Map size: {config.size()} entries\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set: Unique value collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a set to track active IDs\n",
    "active_ids = Set(mem, \"active_ids\", capacity=32, dtype=np.int32)\n",
    "\n",
    "# Add some IDs\n",
    "ids_to_add = [101, 102, 103, 102, 104]  # Note: 102 appears twice\n",
    "for id_val in ids_to_add:\n",
    "    if active_ids.insert(id_val):\n",
    "        print(f\"Added ID: {id_val}\")\n",
    "    else:\n",
    "        print(f\"ID already exists: {id_val}\")\n",
    "\n",
    "print(f\"\\nActive IDs: {active_ids.to_list()}\")\n",
    "print(f\"Set size: {active_ids.size()} unique elements\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Codata Structures\n",
    "\n",
    "### Future: Async computation results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a future for async result\n",
    "result_future = Future(mem, \"computation_result\", dtype=np.float64)\n",
    "\n",
    "def compute_async():\n",
    "    \"\"\"Simulate async computation in another process\"\"\"\n",
    "    mem = Memory(\"/demo_memory\")\n",
    "    future = Future(mem, \"computation_result\", dtype=np.float64, open_existing=True)\n",
    "    \n",
    "    # Simulate computation\n",
    "    time.sleep(0.5)\n",
    "    result = 3.14159\n",
    "    \n",
    "    # Set the result\n",
    "    future.set(result)\n",
    "    print(f\"Computation complete: {result}\")\n",
    "\n",
    "# Start async computation\n",
    "process = Process(target=compute_async)\n",
    "process.start()\n",
    "\n",
    "# Wait for result\n",
    "print(\"Waiting for computation...\")\n",
    "result = result_future.get(timeout=2.0)\n",
    "print(f\"Got result: {result}\")\n",
    "\n",
    "process.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lazy: Deferred evaluation with memoization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create lazy-evaluated value\n",
    "expensive_calc = Lazy(mem, \"expensive_calc\", dtype=np.float64)\n",
    "\n",
    "def expensive_computation():\n",
    "    \"\"\"Simulate expensive computation\"\"\"\n",
    "    print(\"Starting expensive computation...\")\n",
    "    time.sleep(0.2)  # Simulate work\n",
    "    return 42.0\n",
    "\n",
    "# Initialize with computation (not executed yet)\n",
    "if not expensive_calc.is_computed():\n",
    "    expensive_calc.init(expensive_computation)\n",
    "    print(\"Lazy value initialized (not computed)\")\n",
    "\n",
    "# First access triggers computation\n",
    "print(f\"\\nFirst access: {expensive_calc.force()}\")\n",
    "\n",
    "# Second access uses memoized value\n",
    "print(f\"Second access (memoized): {expensive_calc.force()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ring: Circular buffer for streaming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a ring buffer for sensor data\n",
    "sensor_stream = Ring(mem, \"sensor_data\", capacity=100, dtype=np.float32)\n",
    "\n",
    "# Producer: write sensor readings\n",
    "print(\"Writing sensor data...\")\n",
    "for i in range(10):\n",
    "    reading = 100.0 + i * 0.1\n",
    "    sensor_stream.push(reading)\n",
    "    print(f\"  Wrote: {reading:.1f}\")\n",
    "\n",
    "print(f\"\\nRing buffer size: {sensor_stream.size()} readings\")\n",
    "\n",
    "# Consumer: read sensor data\n",
    "print(\"\\nReading sensor data:\")\n",
    "data = sensor_stream.read(max_bytes=5 * 4)  # Read 5 floats\n",
    "if data is not None:\n",
    "    for value in data:\n",
    "        print(f\"  Read: {value:.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Channel: CSP-style synchronous communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create buffered channel for task distribution\n",
    "task_channel = Channel(mem, \"tasks\", capacity=5, dtype=np.int32)\n",
    "\n",
    "def worker_process():\n",
    "    \"\"\"Worker that processes tasks from channel\"\"\"\n",
    "    mem = Memory(\"/demo_memory\")\n",
    "    tasks = Channel(mem, \"tasks\", dtype=np.int32, open_existing=True)\n",
    "    \n",
    "    while True:\n",
    "        task_id = tasks.receive(timeout=1.0)\n",
    "        if task_id is None:\n",
    "            break\n",
    "        print(f\"  Worker: Processing task {task_id}\")\n",
    "        time.sleep(0.1)  # Simulate work\n",
    "\n",
    "# Start worker\n",
    "worker = Process(target=worker_process)\n",
    "worker.start()\n",
    "\n",
    "# Send tasks\n",
    "print(\"Sending tasks to worker...\")\n",
    "for task_id in range(1, 4):\n",
    "    task_channel.send(task_id)\n",
    "    print(f\"Sent task {task_id}\")\n",
    "\n",
    "# Close channel and wait for worker\n",
    "time.sleep(0.5)\n",
    "task_channel.close()\n",
    "worker.join(timeout=2.0)\n",
    "if worker.is_alive():\n",
    "    worker.terminate()\n",
    "print(\"\\nWorker finished\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Cross-Process Communication\n",
    "\n",
    "### Producer-Consumer Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def producer(name):\n",
    "    \"\"\"Producer process that generates data\"\"\"\n",
    "    mem = Memory(\"/demo_memory\")\n",
    "    queue = Queue(mem, \"shared_queue\", dtype=np.int32, open_existing=True)\n",
    "    \n",
    "    for i in range(3):\n",
    "        value = hash(name) % 1000 + i\n",
    "        while not queue.push(value):\n",
    "            time.sleep(0.01)\n",
    "        print(f\"  {name}: Produced {value}\")\n",
    "        time.sleep(0.1)\n",
    "\n",
    "def consumer(name):\n",
    "    \"\"\"Consumer process that processes data\"\"\"\n",
    "    mem = Memory(\"/demo_memory\")\n",
    "    queue = Queue(mem, \"shared_queue\", dtype=np.int32, open_existing=True)\n",
    "    \n",
    "    consumed = 0\n",
    "    while consumed < 3:\n",
    "        value = queue.pop()\n",
    "        if value is not None:\n",
    "            print(f\"  {name}: Consumed {value}\")\n",
    "            consumed += 1\n",
    "        else:\n",
    "            time.sleep(0.01)\n",
    "\n",
    "# Create shared queue\n",
    "shared_queue = Queue(mem, \"shared_queue\", capacity=10, dtype=np.int32)\n",
    "print(\"Starting producer-consumer demo...\\n\")\n",
    "\n",
    "# Start producers and consumers\n",
    "producers = [Process(target=producer, args=(f\"Producer{i}\",)) for i in range(2)]\n",
    "consumers = [Process(target=consumer, args=(f\"Consumer{i}\",)) for i in range(2)]\n",
    "\n",
    "for p in producers + consumers:\n",
    "    p.start()\n",
    "\n",
    "for p in producers + consumers:\n",
    "    p.join(timeout=2.0)\n",
    "    if p.is_alive():\n",
    "        p.terminate()\n",
    "\n",
    "print(\"\\nDemo complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Publish-Subscribe Pattern"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def publisher():\n",
    "    \"\"\"Publisher that broadcasts events\"\"\"\n",
    "    mem = Memory(\"/demo_memory\")\n",
    "    events = Ring(mem, \"event_stream\", capacity=100, dtype=np.int32, open_existing=True)\n",
    "    \n",
    "    for i in range(5):\n",
    "        event_id = 1000 + i\n",
    "        events.push(event_id)\n",
    "        print(f\"Published event: {event_id}\")\n",
    "        time.sleep(0.1)\n",
    "\n",
    "def subscriber(name):\n",
    "    \"\"\"Subscriber that receives events\"\"\"\n",
    "    mem = Memory(\"/demo_memory\")\n",
    "    events = Ring(mem, \"event_stream\", capacity=100, dtype=np.int32, open_existing=True)\n",
    "    \n",
    "    # Track our read position\n",
    "    last_size = 0\n",
    "    events_received = 0\n",
    "    \n",
    "    while events_received < 5:\n",
    "        current_size = events.size()\n",
    "        if current_size > last_size:\n",
    "            # New events available\n",
    "            new_events = events.read(max_bytes=(current_size - last_size) * 4)\n",
    "            if new_events is not None:\n",
    "                for event in new_events:\n",
    "                    print(f\"  {name}: Received event {event}\")\n",
    "                    events_received += 1\n",
    "            last_size = current_size\n",
    "        time.sleep(0.05)\n",
    "\n",
    "# Create event stream\n",
    "event_stream = Ring(mem, \"event_stream\", capacity=100, dtype=np.int32)\n",
    "print(\"Starting publish-subscribe demo...\\n\")\n",
    "\n",
    "# Start publisher and subscribers\n",
    "pub = Process(target=publisher)\n",
    "subs = [Process(target=subscriber, args=(f\"Subscriber{i}\",)) for i in range(2)]\n",
    "\n",
    "pub.start()\n",
    "for s in subs:\n",
    "    s.start()\n",
    "\n",
    "pub.join(timeout=2.0)\n",
    "for s in subs:\n",
    "    s.join(timeout=2.0)\n",
    "    if s.is_alive():\n",
    "        s.terminate()\n",
    "\n",
    "print(\"\\nDemo complete\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Performance Comparison\n",
    "\n",
    "### ZeroIPC vs Traditional IPC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "from multiprocessing import Queue as MPQueue\n",
    "\n",
    "# Test data\n",
    "data_size = 1000\n",
    "test_data = np.random.rand(data_size).astype(np.float32)\n",
    "\n",
    "print(f\"Benchmarking with {data_size} float32 elements...\\n\")\n",
    "\n",
    "# ZeroIPC shared memory array\n",
    "print(\"ZeroIPC Array (zero-copy):\")\n",
    "start = time.perf_counter()\n",
    "zero_array = Array(mem, \"perf_test\", data_size, dtype=np.float32)\n",
    "for i, val in enumerate(test_data):\n",
    "    zero_array[i] = val\n",
    "result = zero_array[:data_size]\n",
    "zero_time = time.perf_counter() - start\n",
    "print(f\"  Time: {zero_time*1000:.3f} ms\")\n",
    "\n",
    "# Traditional multiprocessing Queue (serialization)\n",
    "print(\"\\nMultiprocessing Queue (pickle serialization):\")\n",
    "mp_queue = MPQueue()\n",
    "start = time.perf_counter()\n",
    "mp_queue.put(test_data)\n",
    "result = mp_queue.get()\n",
    "mp_time = time.perf_counter() - start\n",
    "print(f\"  Time: {mp_time*1000:.3f} ms\")\n",
    "\n",
    "# Performance comparison\n",
    "speedup = mp_time / zero_time\n",
    "print(f\"\\nZeroIPC is {speedup:.1f}x faster for this workload\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Best Practices\n",
    "\n",
    "### Resource Management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use context managers for automatic cleanup\n",
    "print(\"Best Practice: Use context managers\\n\")\n",
    "\n",
    "with Channel(mem, \"auto_channel\", capacity=5, dtype=np.int32) as ch:\n",
    "    ch.send(42)\n",
    "    print(f\"Channel is open: {ch.is_open()}\")\n",
    "    print(f\"Received: {ch.receive()}\")\n",
    "# Channel automatically closed here\n",
    "\n",
    "# Verify it's closed\n",
    "reopened = Channel(mem, \"auto_channel\", dtype=np.int32, open_existing=True)\n",
    "print(f\"\\nChannel after context exit: closed={reopened.is_closed()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Error Handling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate proper error handling\n",
    "print(\"Best Practice: Handle errors gracefully\\n\")\n",
    "\n",
    "# Example 1: Check queue capacity\n",
    "small_queue = Queue(mem, \"small_queue\", capacity=2, dtype=np.int32)\n",
    "\n",
    "for i in range(4):\n",
    "    if small_queue.push(i):\n",
    "        print(f\"Successfully pushed {i}\")\n",
    "    else:\n",
    "        print(f\"Queue full, could not push {i}\")\n",
    "\n",
    "# Example 2: Use timeouts for blocking operations\n",
    "print(\"\\nUsing timeouts:\")\n",
    "future_timeout = Future(mem, \"timeout_test\", dtype=np.int32)\n",
    "result = future_timeout.get(timeout=0.5)\n",
    "if result is None:\n",
    "    print(\"Future timed out (expected)\")\n",
    "else:\n",
    "    print(f\"Got result: {result}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Layout Inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Inspect memory layout\n",
    "print(\"Memory Layout Overview:\")\n",
    "print(f\"Total size: {mem.size:,} bytes\")\n",
    "print(f\"\\nMetadata table:\")\n",
    "print(f\"  Entries used: {mem.table.size()} / {mem.table.capacity()}\")\n",
    "print(f\"\\nRegistered structures:\")\n",
    "\n",
    "# List all structures (would need table iteration API)\n",
    "structures = [\n",
    "    \"temperatures\", \"message_queue\", \"config\", \"active_ids\",\n",
    "    \"computation_result\", \"expensive_calc\", \"sensor_data\", \n",
    "    \"tasks\", \"shared_queue\", \"event_stream\"\n",
    "]\n",
    "\n",
    "for name in structures[:5]:  # Show first 5\n",
    "    entry = mem.table.find(name)\n",
    "    if entry:\n",
    "        print(f\"  {name:20} offset={entry.offset:8} size={entry.size:8} bytes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleanup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up shared memory\n",
    "print(\"Cleaning up shared memory...\")\n",
    "del mem\n",
    "\n",
    "# Remove shared memory file\n",
    "import os\n",
    "shm_path = \"/dev/shm/demo_memory\"\n",
    "if os.path.exists(shm_path):\n",
    "    os.unlink(shm_path)\n",
    "    print(f\"Removed {shm_path}\")\n",
    "\n",
    "print(\"\\nTutorial complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "ZeroIPC provides:\n",
    "- **Zero-copy performance** through shared memory\n",
    "- **Lock-free data structures** for safe concurrent access\n",
    "- **Codata structures** for advanced computation patterns\n",
    "- **Cross-language support** (C++, Python, C)\n",
    "- **Simple API** that feels native to each language\n",
    "\n",
    "Key use cases:\n",
    "- High-frequency trading systems\n",
    "- Real-time sensor data processing\n",
    "- Video/audio streaming pipelines  \n",
    "- Distributed computing frameworks\n",
    "- Inter-process communication in robotics\n",
    "\n",
    "For more information:\n",
    "- GitHub: https://github.com/nullpy/zeroipc\n",
    "- Documentation: See `/docs` in the repository\n",
    "- C++ Examples: `/cpp/examples/`\n",
    "- Python Tests: `/python/tests/`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}